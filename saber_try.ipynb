{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "text",
    "id": "Hjfb3F4k6MW-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saber version: 0.1.0-alpha\n"
     ]
    }
   ],
   "source": [
    "from saber.saber import Saber, Config\n",
    "config = Config('C:/Users/User/config.ini')\n",
    "sb = Saber(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gh5-n16u6MXD",
    "outputId": "2a5ca118-309d-4864-9dd2-b16b333834b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading (single) dataset... Done (163.52 seconds).\n"
     ]
    }
   ],
   "source": [
    "sb.load_dataset('C:/Users/User') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHHizhaa6MXM",
    "outputId": "9dca5d46-6a7c-416e-a4cb-bf9f1775250b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the multi-task BiLSTM-CRF model... Done (53.60 seconds).\n"
     ]
    }
   ],
   "source": [
    "sb.build(model_name='MT-LSTM-CRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdlZ0l596MXb",
    "outputId": "3b017157-f191-43ab-ffa7-60882290d69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train/test/valid strategy...\n",
      "Global epoch: 1/50\n",
      "--------------------\n",
      "Train on 4831 samples, validate on 537 samples\n",
      "Epoch 1/1\n",
      "4831/4831 [==============================] - ETA: 3:30:19 - loss: 20.677 - ETA: 2:04:55 - loss: 20.337 - ETA: 1:34:14 - loss: 20.506 - ETA: 1:16:25 - loss: 23.347 - ETA: 1:05:28 - loss: 21.755 - ETA: 56:36 - loss: 21.6409  - ETA: 50:18 - loss: 20.342 - ETA: 46:33 - loss: 20.313 - ETA: 42:49 - loss: 20.009 - ETA: 39:42 - loss: 20.503 - ETA: 37:14 - loss: 20.184 - ETA: 35:47 - loss: 19.980 - ETA: 33:57 - loss: 19.267 - ETA: 32:21 - loss: 18.980 - ETA: 31:35 - loss: 18.953 - ETA: 31:01 - loss: 18.733 - ETA: 30:21 - loss: 18.733 - ETA: 29:46 - loss: 18.710 - ETA: 28:43 - loss: 18.704 - ETA: 27:45 - loss: 18.511 - ETA: 26:55 - loss: 18.539 - ETA: 26:15 - loss: 18.465 - ETA: 25:36 - loss: 18.699 - ETA: 24:57 - loss: 18.614 - ETA: 24:21 - loss: 18.462 - ETA: 23:47 - loss: 18.709 - ETA: 23:15 - loss: 18.613 - ETA: 22:46 - loss: 18.379 - ETA: 22:17 - loss: 18.352 - ETA: 21:49 - loss: 18.228 - ETA: 21:23 - loss: 18.365 - ETA: 20:58 - loss: 18.265 - ETA: 20:34 - loss: 18.108 - ETA: 20:10 - loss: 18.460 - ETA: 19:48 - loss: 18.575 - ETA: 19:27 - loss: 18.658 - ETA: 19:08 - loss: 18.700 - ETA: 18:49 - loss: 18.680 - ETA: 18:40 - loss: 18.656 - ETA: 18:39 - loss: 18.636 - ETA: 18:30 - loss: 18.611 - ETA: 18:23 - loss: 18.614 - ETA: 18:04 - loss: 18.728 - ETA: 17:56 - loss: 18.777 - ETA: 17:47 - loss: 18.914 - ETA: 17:38 - loss: 18.809 - ETA: 17:29 - loss: 18.746 - ETA: 17:21 - loss: 18.682 - ETA: 17:06 - loss: 18.689 - ETA: 16:59 - loss: 18.609 - ETA: 16:48 - loss: 18.588 - ETA: 16:39 - loss: 18.565 - ETA: 16:22 - loss: 18.484 - ETA: 16:11 - loss: 18.422 - ETA: 16:00 - loss: 18.475 - ETA: 15:49 - loss: 18.482 - ETA: 15:39 - loss: 18.474 - ETA: 15:28 - loss: 18.326 - ETA: 15:19 - loss: 18.299 - ETA: 15:03 - loss: 18.292 - ETA: 14:47 - loss: 18.238 - ETA: 14:37 - loss: 18.281 - ETA: 14:22 - loss: 18.341 - ETA: 14:07 - loss: 18.394 - ETA: 13:52 - loss: 18.401 - ETA: 13:38 - loss: 18.370 - ETA: 13:24 - loss: 18.384 - ETA: 13:13 - loss: 18.382 - ETA: 12:59 - loss: 18.425 - ETA: 12:46 - loss: 18.478 - ETA: 12:32 - loss: 18.412 - ETA: 12:19 - loss: 18.381 - ETA: 12:06 - loss: 18.343 - ETA: 11:53 - loss: 18.334 - ETA: 11:40 - loss: 18.272 - ETA: 11:28 - loss: 18.247 - ETA: 11:16 - loss: 18.173 - ETA: 11:07 - loss: 18.114 - ETA: 10:55 - loss: 18.075 - ETA: 10:43 - loss: 18.033 - ETA: 10:31 - loss: 18.048 - ETA: 10:19 - loss: 18.020 - ETA: 10:08 - loss: 18.055 - ETA: 9:56 - loss: 17.983 - ETA: 9:45 - loss: 17.99 - ETA: 9:34 - loss: 18.02 - ETA: 9:23 - loss: 18.01 - ETA: 9:13 - loss: 17.98 - ETA: 9:02 - loss: 17.96 - ETA: 8:51 - loss: 17.99 - ETA: 8:41 - loss: 18.14 - ETA: 8:30 - loss: 18.11 - ETA: 8:20 - loss: 18.08 - ETA: 8:09 - loss: 18.07 - ETA: 7:59 - loss: 18.04 - ETA: 7:49 - loss: 18.04 - ETA: 7:39 - loss: 18.04 - ETA: 7:29 - loss: 18.03 - ETA: 7:20 - loss: 18.08 - ETA: 7:10 - loss: 18.10 - ETA: 7:00 - loss: 18.22 - ETA: 6:51 - loss: 18.21 - ETA: 6:41 - loss: 18.22 - ETA: 6:32 - loss: 18.19 - ETA: 6:22 - loss: 18.16 - ETA: 6:13 - loss: 18.20 - ETA: 6:04 - loss: 18.21 - ETA: 5:55 - loss: 18.19 - ETA: 5:45 - loss: 18.26 - ETA: 5:36 - loss: 18.23 - ETA: 5:27 - loss: 18.22 - ETA: 5:18 - loss: 18.20 - ETA: 5:09 - loss: 18.20 - ETA: 5:00 - loss: 18.24 - ETA: 4:52 - loss: 18.24 - ETA: 4:43 - loss: 18.25 - ETA: 4:34 - loss: 18.31 - ETA: 4:26 - loss: 18.29 - ETA: 4:17 - loss: 18.25 - ETA: 4:10 - loss: 18.22 - ETA: 4:01 - loss: 18.27 - ETA: 3:53 - loss: 18.25 - ETA: 3:44 - loss: 18.21 - ETA: 3:36 - loss: 18.23 - ETA: 3:27 - loss: 18.22 - ETA: 3:19 - loss: 18.21 - ETA: 3:10 - loss: 18.20 - ETA: 3:02 - loss: 18.17 - ETA: 2:54 - loss: 18.16 - ETA: 2:46 - loss: 18.11 - ETA: 2:37 - loss: 18.09 - ETA: 2:29 - loss: 18.07 - ETA: 2:21 - loss: 18.06 - ETA: 2:13 - loss: 18.12 - ETA: 2:05 - loss: 18.11 - ETA: 1:57 - loss: 18.09 - ETA: 1:49 - loss: 18.09 - ETA: 1:41 - loss: 18.07 - ETA: 1:33 - loss: 18.06 - ETA: 1:25 - loss: 18.05 - ETA: 1:17 - loss: 18.09 - ETA: 1:09 - loss: 18.11 - ETA: 1:01 - loss: 18.08 - ETA: 53s - loss: 18.0734 - ETA: 46s - loss: 18.061 - ETA: 38s - loss: 18.025 - ETA: 30s - loss: 18.075 - ETA: 22s - loss: 18.094 - ETA: 15s - loss: 18.074 - ETA: 7s - loss: 18.094 - 1200s 248ms/step - loss: 18.0833 - val_loss: 17.9287\n",
      "+---------------------------------------------------+\n",
      "|                       TRAIN                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |     0.00% |  0.00% |  0.00% |    1150 |\n",
      "| Disease   |    61.05% | 14.69% | 23.68% |    3949 |\n",
      "| MACRO_AVG |    30.53% |  7.34% | 11.84% |    5099 |\n",
      "| MICRO_AVG |    61.05% | 11.37% | 19.18% |    5099 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "+---------------------------------------------------+\n",
      "|                       VALID                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |     0.00% |  0.00% |  0.00% |     105 |\n",
      "| Disease   |    54.95% | 11.29% | 18.73% |     443 |\n",
      "| MACRO_AVG |    27.47% |  5.64% |  9.36% |     548 |\n",
      "| MICRO_AVG |    54.95% |  9.12% | 15.65% |     548 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "+---------------------------------------------------+\n",
      "|                        TEST                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |     0.00% |  0.00% |  0.00% |     534 |\n",
      "| Disease   |    45.65% |  8.93% | 14.93% |    2173 |\n",
      "| MACRO_AVG |    22.82% |  4.46% |  7.47% |    2707 |\n",
      "| MICRO_AVG |    45.65% |  7.17% | 12.39% |    2707 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "Global epoch: 2/50\n",
      "--------------------\n",
      "Train on 4831 samples, validate on 537 samples\n",
      "Epoch 2/2\n",
      "4831/4831 [==============================] - ETA: 39:51 - loss: 21.313 - ETA: 28:47 - loss: 18.110 - ETA: 24:01 - loss: 17.245 - ETA: 21:35 - loss: 17.805 - ETA: 20:09 - loss: 17.695 - ETA: 19:03 - loss: 17.988 - ETA: 18:20 - loss: 18.215 - ETA: 17:45 - loss: 17.655 - ETA: 17:17 - loss: 18.427 - ETA: 16:52 - loss: 19.166 - ETA: 16:29 - loss: 18.935 - ETA: 16:08 - loss: 18.724 - ETA: 15:52 - loss: 18.941 - ETA: 15:37 - loss: 19.033 - ETA: 15:23 - loss: 18.592 - ETA: 15:08 - loss: 18.458 - ETA: 14:56 - loss: 18.346 - ETA: 14:43 - loss: 18.134 - ETA: 14:32 - loss: 18.069 - ETA: 14:23 - loss: 17.816 - ETA: 14:12 - loss: 17.990 - ETA: 14:01 - loss: 17.809 - ETA: 13:52 - loss: 17.924 - ETA: 13:42 - loss: 18.396 - ETA: 13:32 - loss: 18.218 - ETA: 13:24 - loss: 18.212 - ETA: 13:15 - loss: 18.448 - ETA: 13:07 - loss: 18.277 - ETA: 12:58 - loss: 18.208 - ETA: 12:50 - loss: 18.176 - ETA: 12:44 - loss: 18.319 - ETA: 12:36 - loss: 18.596 - ETA: 12:29 - loss: 18.459 - ETA: 12:22 - loss: 18.346 - ETA: 12:14 - loss: 18.377 - ETA: 12:07 - loss: 18.547 - ETA: 12:00 - loss: 18.532 - ETA: 11:53 - loss: 18.595 - ETA: 11:45 - loss: 18.495 - ETA: 11:38 - loss: 18.322 - ETA: 11:32 - loss: 18.224 - ETA: 11:25 - loss: 18.133 - ETA: 11:18 - loss: 18.194 - ETA: 11:12 - loss: 18.129 - ETA: 11:05 - loss: 18.061 - ETA: 10:58 - loss: 17.984 - ETA: 10:52 - loss: 18.022 - ETA: 10:45 - loss: 17.943 - ETA: 10:38 - loss: 18.067 - ETA: 10:31 - loss: 17.979 - ETA: 10:24 - loss: 17.987 - ETA: 10:18 - loss: 17.875 - ETA: 10:11 - loss: 17.930 - ETA: 10:04 - loss: 17.911 - ETA: 9:57 - loss: 17.865 - ETA: 9:51 - loss: 17.88 - ETA: 9:44 - loss: 17.85 - ETA: 9:38 - loss: 17.98 - ETA: 9:31 - loss: 17.93 - ETA: 9:25 - loss: 17.84 - ETA: 9:19 - loss: 17.80 - ETA: 9:12 - loss: 17.79 - ETA: 9:06 - loss: 17.77 - ETA: 8:59 - loss: 17.79 - ETA: 8:53 - loss: 17.77 - ETA: 8:46 - loss: 17.73 - ETA: 8:39 - loss: 17.70 - ETA: 8:33 - loss: 17.85 - ETA: 8:26 - loss: 17.79 - ETA: 8:20 - loss: 17.83 - ETA: 8:13 - loss: 17.82 - ETA: 8:07 - loss: 17.85 - ETA: 8:00 - loss: 17.88 - ETA: 7:54 - loss: 17.87 - ETA: 7:48 - loss: 17.83 - ETA: 7:42 - loss: 17.84 - ETA: 7:35 - loss: 17.83 - ETA: 7:29 - loss: 17.78 - ETA: 7:22 - loss: 17.70 - ETA: 7:16 - loss: 17.69 - ETA: 7:10 - loss: 17.68 - ETA: 7:03 - loss: 17.65 - ETA: 6:57 - loss: 17.62 - ETA: 6:51 - loss: 17.64 - ETA: 6:44 - loss: 17.64 - ETA: 6:38 - loss: 17.57 - ETA: 6:32 - loss: 17.61 - ETA: 6:26 - loss: 17.62 - ETA: 6:19 - loss: 17.60 - ETA: 6:13 - loss: 17.57 - ETA: 6:07 - loss: 17.60 - ETA: 6:01 - loss: 17.65 - ETA: 5:55 - loss: 17.66 - ETA: 5:49 - loss: 17.63 - ETA: 5:43 - loss: 17.64 - ETA: 5:37 - loss: 17.59 - ETA: 5:30 - loss: 17.71 - ETA: 5:24 - loss: 17.70 - ETA: 5:18 - loss: 17.72 - ETA: 5:12 - loss: 17.72 - ETA: 5:05 - loss: 17.73 - ETA: 4:59 - loss: 17.78 - ETA: 4:53 - loss: 17.79 - ETA: 4:47 - loss: 17.77 - ETA: 4:41 - loss: 17.83 - ETA: 4:34 - loss: 17.86 - ETA: 4:28 - loss: 17.82 - ETA: 4:22 - loss: 17.83 - ETA: 4:16 - loss: 17.83 - ETA: 4:10 - loss: 17.79 - ETA: 4:04 - loss: 17.77 - ETA: 3:58 - loss: 17.80 - ETA: 3:51 - loss: 17.85 - ETA: 3:45 - loss: 17.80 - ETA: 3:39 - loss: 17.82 - ETA: 3:33 - loss: 17.88 - ETA: 3:27 - loss: 17.90 - ETA: 3:21 - loss: 17.88 - ETA: 3:15 - loss: 17.83 - ETA: 3:09 - loss: 17.83 - ETA: 3:02 - loss: 17.78 - ETA: 2:56 - loss: 17.77 - ETA: 2:50 - loss: 17.78 - ETA: 2:44 - loss: 17.76 - ETA: 2:38 - loss: 17.72 - ETA: 2:32 - loss: 17.67 - ETA: 2:26 - loss: 17.72 - ETA: 2:20 - loss: 17.71 - ETA: 2:14 - loss: 17.71 - ETA: 2:07 - loss: 17.72 - ETA: 2:01 - loss: 17.69 - ETA: 1:55 - loss: 17.71 - ETA: 1:49 - loss: 17.70 - ETA: 1:43 - loss: 17.66 - ETA: 1:37 - loss: 17.62 - ETA: 1:31 - loss: 17.61 - ETA: 1:25 - loss: 17.62 - ETA: 1:19 - loss: 17.61 - ETA: 1:12 - loss: 17.61 - ETA: 1:06 - loss: 17.62 - ETA: 1:00 - loss: 17.64 - ETA: 54s - loss: 17.6531 - ETA: 48s - loss: 17.664 - ETA: 42s - loss: 17.653 - ETA: 36s - loss: 17.687 - ETA: 30s - loss: 17.680 - ETA: 24s - loss: 17.661 - ETA: 18s - loss: 17.644 - ETA: 11s - loss: 17.633 - ETA: 5s - loss: 17.660 - 954s 197ms/step - loss: 17.6988 - val_loss: 17.8294\n",
      "+---------------------------------------------------+\n",
      "|                       TRAIN                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |    96.35% | 78.00% | 86.21% |    1150 |\n",
      "| Disease   |    66.29% | 67.64% | 66.96% |    3949 |\n",
      "| MACRO_AVG |    81.32% | 72.82% | 76.58% |    5099 |\n",
      "| MICRO_AVG |    71.94% | 69.97% | 70.94% |    5099 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "+---------------------------------------------------+\n",
      "|                       VALID                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |    90.48% | 18.10% | 30.16% |     105 |\n",
      "| Disease   |    62.44% | 57.79% | 60.02% |     443 |\n",
      "| MACRO_AVG |    76.46% | 37.94% | 45.09% |     548 |\n",
      "| MICRO_AVG |    63.81% | 50.18% | 56.18% |     548 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "+---------------------------------------------------+\n",
      "|                        TEST                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |    98.18% | 50.56% | 66.75% |     534 |\n",
      "| Disease   |    55.38% | 48.32% | 51.61% |    2173 |\n",
      "| MACRO_AVG |    76.78% | 49.44% | 59.18% |    2707 |\n",
      "| MICRO_AVG |    60.80% | 48.76% | 54.12% |    2707 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "...",
      "Global epoch: 50/50\n",
      "--------------------\n",
      "Train on 4831 samples, validate on 537 samples\n",
      "Epoch 50/50\n",
      "4831/4831 [==============================] - ETA: 30:33 - loss: 15.110 - ETA: 23:18 - loss: 15.396 - ETA: 20:26 - loss: 16.641 - ETA: 19:00 - loss: 18.632 - ETA: 17:59 - loss: 17.715 - ETA: 17:20 - loss: 18.059 - ETA: 16:51 - loss: 18.296 - ETA: 16:32 - loss: 18.089 - ETA: 16:12 - loss: 18.382 - ETA: 15:55 - loss: 17.756 - ETA: 15:41 - loss: 17.492 - ETA: 15:26 - loss: 17.171 - ETA: 15:14 - loss: 17.377 - ETA: 15:01 - loss: 17.454 - ETA: 14:50 - loss: 17.276 - ETA: 14:39 - loss: 17.508 - ETA: 14:29 - loss: 17.719 - ETA: 14:21 - loss: 17.516 - ETA: 14:12 - loss: 17.285 - ETA: 14:04 - loss: 17.181 - ETA: 13:54 - loss: 17.256 - ETA: 13:46 - loss: 17.120 - ETA: 13:37 - loss: 17.359 - ETA: 13:30 - loss: 17.478 - ETA: 13:21 - loss: 17.603 - ETA: 13:13 - loss: 17.480 - ETA: 13:06 - loss: 17.532 - ETA: 12:58 - loss: 17.414 - ETA: 12:52 - loss: 17.500 - ETA: 12:46 - loss: 17.361 - ETA: 12:39 - loss: 17.296 - ETA: 12:32 - loss: 17.243 - ETA: 12:25 - loss: 17.387 - ETA: 12:18 - loss: 17.418 - ETA: 12:11 - loss: 17.392 - ETA: 12:04 - loss: 17.278 - ETA: 11:57 - loss: 17.251 - ETA: 11:50 - loss: 17.178 - ETA: 11:43 - loss: 17.373 - ETA: 11:37 - loss: 17.316 - ETA: 11:30 - loss: 17.209 - ETA: 11:23 - loss: 17.294 - ETA: 11:16 - loss: 17.154 - ETA: 11:10 - loss: 17.196 - ETA: 11:03 - loss: 17.237 - ETA: 10:56 - loss: 17.368 - ETA: 10:49 - loss: 17.563 - ETA: 10:43 - loss: 17.527 - ETA: 10:36 - loss: 17.670 - ETA: 10:30 - loss: 17.620 - ETA: 10:23 - loss: 17.598 - ETA: 10:17 - loss: 17.562 - ETA: 10:10 - loss: 17.809 - ETA: 10:04 - loss: 17.732 - ETA: 9:58 - loss: 17.894 - ETA: 9:51 - loss: 17.84 - ETA: 9:45 - loss: 17.80 - ETA: 9:38 - loss: 17.71 - ETA: 9:32 - loss: 17.72 - ETA: 9:25 - loss: 17.69 - ETA: 9:19 - loss: 17.61 - ETA: 9:12 - loss: 17.50 - ETA: 9:06 - loss: 17.67 - ETA: 8:59 - loss: 17.69 - ETA: 8:53 - loss: 17.73 - ETA: 8:46 - loss: 17.78 - ETA: 8:39 - loss: 17.71 - ETA: 8:33 - loss: 17.68 - ETA: 8:26 - loss: 17.68 - ETA: 8:20 - loss: 17.74 - ETA: 8:14 - loss: 17.74 - ETA: 8:08 - loss: 17.70 - ETA: 8:02 - loss: 17.62 - ETA: 7:55 - loss: 17.63 - ETA: 7:49 - loss: 17.56 - ETA: 7:42 - loss: 17.55 - ETA: 7:36 - loss: 17.51 - ETA: 7:30 - loss: 17.47 - ETA: 7:23 - loss: 17.45 - ETA: 7:17 - loss: 17.45 - ETA: 7:11 - loss: 17.41 - ETA: 7:05 - loss: 17.42 - ETA: 6:58 - loss: 17.38 - ETA: 6:52 - loss: 17.49 - ETA: 6:46 - loss: 17.47 - ETA: 6:40 - loss: 17.48 - ETA: 6:34 - loss: 17.44 - ETA: 6:27 - loss: 17.50 - ETA: 6:21 - loss: 17.49 - ETA: 6:15 - loss: 17.46 - ETA: 6:09 - loss: 17.49 - ETA: 6:02 - loss: 17.46 - ETA: 5:56 - loss: 17.51 - ETA: 5:50 - loss: 17.51 - ETA: 5:44 - loss: 17.51 - ETA: 5:38 - loss: 17.47 - ETA: 5:32 - loss: 17.46 - ETA: 5:25 - loss: 17.46 - ETA: 5:19 - loss: 17.43 - ETA: 5:13 - loss: 17.43 - ETA: 5:07 - loss: 17.45 - ETA: 5:01 - loss: 17.45 - ETA: 4:54 - loss: 17.42 - ETA: 4:48 - loss: 17.42 - ETA: 4:42 - loss: 17.39 - ETA: 4:36 - loss: 17.40 - ETA: 4:30 - loss: 17.46 - ETA: 4:23 - loss: 17.46 - ETA: 4:17 - loss: 17.42 - ETA: 4:11 - loss: 17.42 - ETA: 4:05 - loss: 17.39 - ETA: 3:59 - loss: 17.45 - ETA: 3:53 - loss: 17.50 - ETA: 3:46 - loss: 17.52 - ETA: 3:40 - loss: 17.54 - ETA: 3:34 - loss: 17.57 - ETA: 3:28 - loss: 17.57 - ETA: 3:22 - loss: 17.60 - ETA: 3:16 - loss: 17.62 - ETA: 3:09 - loss: 17.60 - ETA: 3:03 - loss: 17.57 - ETA: 2:57 - loss: 17.61 - ETA: 2:51 - loss: 17.59 - ETA: 2:45 - loss: 17.58 - ETA: 2:39 - loss: 17.57 - ETA: 2:32 - loss: 17.54 - ETA: 2:26 - loss: 17.53 - ETA: 2:20 - loss: 17.56 - ETA: 2:15 - loss: 17.55 - ETA: 2:09 - loss: 17.53 - ETA: 2:02 - loss: 17.56 - ETA: 1:56 - loss: 17.52 - ETA: 1:50 - loss: 17.49 - ETA: 1:44 - loss: 17.51 - ETA: 1:38 - loss: 17.48 - ETA: 1:31 - loss: 17.50 - ETA: 1:25 - loss: 17.50 - ETA: 1:19 - loss: 17.47 - ETA: 1:13 - loss: 17.45 - ETA: 1:07 - loss: 17.46 - ETA: 1:01 - loss: 17.44 - ETA: 55s - loss: 17.4399 - ETA: 48s - loss: 17.460 - ETA: 42s - loss: 17.516 - ETA: 36s - loss: 17.503 - ETA: 30s - loss: 17.464 - ETA: 24s - loss: 17.446 - ETA: 18s - loss: 17.444 - ETA: 12s - loss: 17.471 - ETA: 5s - loss: 17.450 - 959s 198ms/step - loss: 17.4635 - val_loss: 17.9972\n",
      "+----------------------------------------------------+\n",
      "|                       TRAIN                        |\n",
      "+-----------+-----------+---------+--------+---------+\n",
      "| Label     | Precision |  Recall |     F1 | Support |\n",
      "+-----------+-----------+---------+--------+---------+\n",
      "| Drug      |    99.91% | 100.00% | 99.96% |    1150 |\n",
      "| Disease   |    99.52% |  99.75% | 99.63% |    3949 |\n",
      "| MACRO_AVG |    99.72% |  99.87% | 99.79% |    5099 |\n",
      "| MICRO_AVG |    99.61% |  99.80% | 99.71% |    5099 |\n",
      "+-----------+-----------+---------+--------+---------+\n",
      "+---------------------------------------------------+\n",
      "|                       VALID                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |    80.95% | 32.38% | 46.26% |     105 |\n",
      "| Disease   |    62.00% | 62.98% | 62.49% |     443 |\n",
      "| MACRO_AVG |    71.48% | 47.68% | 54.37% |     548 |\n",
      "| MICRO_AVG |    63.62% | 57.12% | 60.19% |     548 |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "+---------------------------------------------------+\n",
      "|                        TEST                       |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Label     | Precision | Recall |     F1 | Support |\n",
      "+-----------+-----------+--------+--------+---------+\n",
      "| Drug      |    82.70% | 60.86% | 70.12% |     534 |\n",
      "| Disease   |    57.87% | 55.50% | 56.66% |    2173 |\n",
      "| MACRO_AVG |    70.28% | 58.18% | 63.39% |    2707 |\n",
      "| MICRO_AVG |    61.81% | 56.56% | 59.07% |    2707 |\n",
      "+-----------+-----------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "sb.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5C_sTRr6MXp",
    "outputId": "9876b1f4-4449-4f23-8c74-4ce0cfa6645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model... Done (496.69 seconds).\n",
      "Model was saved to C:\\Users\\User\\output\n"
     ]
    }
   ],
   "source": [
    "sb.save('C:/Users/User/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jbw59Yv16MX2",
    "outputId": "69bc514b-4241-4e41-fbf5-ac6da6716961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... Unzipping... Done (627.85 seconds).\n"
     ]
    }
   ],
   "source": [
    "del sb\n",
    "saber = Saber()\n",
    "saber.load('C:/Users/User/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5042,
     "status": "error",
     "timestamp": 1573984175089,
     "user": {
      "displayName": "Алина Ситтикова",
      "photoUrl": "",
      "userId": "08954544000680941339"
     },
     "user_tz": -180
    },
    "id": "Yh51jMIN6MYQ",
    "outputId": "0dc6ae03-4263-4343-e532-3bc6a6324217"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('I', 'O'), ('feel', 'O'), ('a', 'O'), ('bit', 'B-Disease'), ('drowsy', 'I-Disease'), ('&', 'O'), ('have', 'O'), ('a', 'O'), ('little', 'B-Disease'), ('blurred', 'I-Disease'), ('vision', 'I-Disease'), (',', 'O'), ('so', 'O'), ('far', 'O'), ('no', 'O'), ('gastric', 'B-Disease'), ('problems', 'I-Disease'), ('.', 'O')], [('I', 'O'), (\"'\", 'O'), ('ve', 'O'), ('been', 'O'), ('on', 'O'), ('Arthrotec', 'B-Drug'), ('50', 'O'), ('for', 'O'), ('over', 'O'), ('10', 'O'), ('years', 'O'), ('on', 'O'), ('and', 'O'), ('off', 'O'), (',', 'O'), ('only', 'O'), ('taking', 'O'), ('it', 'O'), ('when', 'O'), ('I', 'O'), ('needed', 'O'), ('it', 'O'), ('.', 'O')], ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "conll_parser = ConllCorpusReader('C:/Users/User/Desktop/al/учёба/course', '.csv', ('words', 'pos'))\n",
    "sents = conll_parser.tagged_sents('test.csv')\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "result = []\n",
    "for i in conll_parser.sents('test.csv'):\n",
    "    result.append(TreebankWordDetokenizer().detokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nepfgkqL6Mb2",
    "outputId": "a1344b20-f72b-4398-b53d-66a711067d72",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessor... Done (65.78 seconds).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'I feel a bit drowsy & have a little blurred vision , so far no gastric problems',\n",
       " 'title': '',\n",
       " 'ents': [{'start': 13, 'end': 19, 'text': 'drowsy', 'label': 'Disease'},\n",
       "  {'start': 36, 'end': 50, 'text': 'blurred vision', 'label': 'Disease'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.annotate('I feel a bit drowsy & have a little blurred vision , so far no gastric problems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwwvEuDo6McL"
   },
   "outputs": [],
   "source": [
    "with open('first_result.txt', 'w') as first_out:\n",
    "    for i in result:\n",
    "        first_out.write(str(sb.annotate(i)))\n",
    "        first_out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HoIEfxI6MgR",
    "outputId": "2b42d44f-be89-4a5a-8676-c6707fa44939"
   },
   "outputs": [],
   "source": [
    "def make_new_sents(sentences):\n",
    "    new_sentences = []\n",
    "    part = ''\n",
    "    part_drug=''\n",
    "    for sent in sentences:\n",
    "        new_sent = []    \n",
    "        for elem in sent:\n",
    "            if elem[1]=='B-Disease':\n",
    "                part = elem[0]\n",
    "            elif elem[1]=='I-Disease':\n",
    "                part = part +' '+ elem[0]\n",
    "            elif elem[1]=='B-Drug':\n",
    "                part_drug = elem[0]\n",
    "            elif elem[1]=='I-Drug':\n",
    "                part_drug = part_drug +' '+ elem[0]\n",
    "            else:\n",
    "                if part:\n",
    "                    new_sent.append((part, 'Disease'))\n",
    "                    #new_sent.append(part)\n",
    "                    part = ''\n",
    "                if part_drug:\n",
    "                    new_sent.append((part_drug, 'Drug'))\n",
    "                    part_drug=''\n",
    "                #else:    \n",
    "                #    new_sent.append(elem)\n",
    "        new_sentences.append(new_sent)    \n",
    "    return new_sentences    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FF0qMxOD6MgX",
    "outputId": "fe22927b-6c4c-4f2f-8269-739b74dda032"
   },
   "outputs": [],
   "source": [
    "def print_predictions(filename, sentences):\n",
    "    import ast\n",
    "    with open('correct_pred.txt', 'w') as correct, open('partly_correct.txt', 'w') as partly, open('false_pred.txt', 'w') as fal:\n",
    "        with open(filename) as predicted:\n",
    "            for line, sent in zip(predicted, sentences):\n",
    "                line_as_dict = ast.literal_eval(line)\n",
    "                entities = line_as_dict['ents']\n",
    "                for ent in entities:  \n",
    "                    flag = False\n",
    "                    for elem in sent:\n",
    "                        if (ent['text'] in elem[0] or elem[0] in ent['text']):\n",
    "                            flag = True\n",
    "                            if ent['text'] != elem[0]:\n",
    "                                partly.write(str(ent['text']+'\\t'+elem[0]+'\\n'))\n",
    "                            else:\n",
    "                                correct.write(str(line_as_dict['text']+'\\n'+ent['text']+'\\t'+ent['label']+'\\n\\n'))    \n",
    "                    if not flag:\n",
    "                        fal.write(str(line_as_dict['text']+'\\n'+ent['text']+'\\t'+ent['label']+'\\n\\n'))  \n",
    "    return                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sents = make_new_sents(sents)\n",
    "print_predictions('first_result.txt', new_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_res.txt', 'w') as out:\n",
    "    for i in range(9):\n",
    "        file = 'C:/Users/User/output/User/train_session_sat_oct_19_12_22_17/'+f'epoch_00{i+1}.txt'\n",
    "        with open(file) as infile:\n",
    "            for line in infile:\n",
    "                out.write(line)\n",
    "    for i in range(9, 49):\n",
    "        file = 'C:/Users/User/output/User/train_session_sat_oct_19_12_22_17/'+f'epoch_0{i+1}.txt'\n",
    "        with open(file) as infile:\n",
    "            for line in infile:\n",
    "                out.write(line)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled13.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
